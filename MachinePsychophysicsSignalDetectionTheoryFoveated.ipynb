{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90627f27-ca3b-4172-8dd8-e64766d25b1e",
   "metadata": {},
   "source": [
    "# Run a Machine Psychophysics Experiment Signal Detection Theory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec217ac-6ccc-4712-9fdb-518503c73050",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load requirements\n",
    "import sys, os, distutils.core\n",
    "import torch, detectron2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "import detectron2.structures.boxes as boxes\n",
    "\n",
    "#import coco json ID to label conversion\n",
    "import coco_object_categories\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pickle\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "## Change this based on your filesystem\n",
    "base_folder = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a161ed2f-92a6-4b49-9a8a-097363a7cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the normal nnotation file in coco has 90 categories for some unknown reason. Use the real ones from this text file.\n",
    "anns_file = './train_finetune/coco80annotations.txt'\n",
    "with open(anns_file) as f:\n",
    "    anns = [line.replace('\\n','') for line in f.readlines()]\n",
    "\n",
    "label_converter_dict = {}\n",
    "for i, ann in enumerate(anns):\n",
    "    label_converter_dict[ann] = i #convert to zero-indexed labels\n",
    "#label_converter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84f82aef-04a6-4269-b4c7-1a51f1b6161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000000009590.jpg', '000000009769.jpg', '000000011197.jpg', '000000016439.jpg', '000000018150.jpg', '000000018380.jpg', '000000019042.jpg', '000000061268.jpg', '000000063602.jpg', '000000067616.jpg', '000000119445.jpg', '000000119516.jpg', '000000186422.jpg', '000000203864.jpg', '000000209530.jpg', '000000222299.jpg', '000000226417.jpg', '000000255165.jpg', '000000281409.jpg', '000000311002.jpg', '000000322163.jpg', '000000484351.jpg', '000000491008.jpg', '000000509258.jpg', '000000529148.jpg', '000000545100.jpg']\n"
     ]
    }
   ],
   "source": [
    "## Load In Mongrel Pairs\n",
    "\n",
    "## read in data info\n",
    "bbx_list = pd.read_csv('./psychophysics_experiment/cocop_bbx_fixations_new.csv')\n",
    "\n",
    "#imlist = list(set(list(bbx_list['image_name'])))\n",
    "#imlist = ['000000009590.jpg','000000529148.jpg','000000545100.jpg','000000255165.jpg','000000322163.jpg'] #'000000311002.jpg', <- fix this one, it's 10 mongrels of the mask\n",
    "imlist = ['000000009590.jpg','000000009769.jpg','000000011197.jpg','000000016439.jpg',\n",
    "'000000018150.jpg','000000018380.jpg','000000019042.jpg',\n",
    "'000000061268.jpg','000000063602.jpg','000000067616.jpg','000000119445.jpg',\n",
    "'000000119516.jpg','000000186422.jpg','000000203864.jpg',\n",
    "'000000209530.jpg','000000222299.jpg','000000226417.jpg','000000255165.jpg','000000281409.jpg',\n",
    "'000000311002.jpg','000000322163.jpg',\n",
    "'000000484351.jpg','000000491008.jpg','000000509258.jpg','000000529148.jpg','000000545100.jpg']\n",
    "print(imlist)\n",
    "\n",
    "eccs_px = [0,80,160,240,320] \n",
    "eccs_dg = [0,5,10,15,20]\n",
    "\n",
    "\n",
    "\n",
    "#Uniform\n",
    "#imfolder_present = f'{base_dir}/final_experiment_multiple_mongrel_images_present/'\n",
    "#imfolder_absent = f'{base_dir}/final_experiment_multiple_mongrel_images_absent/'\n",
    "#imfolder_present = imfolder_absent = imfolder = f'{base_dir}cocop_stims3_scoring/uniform/'\n",
    "#psuedofoveated\n",
    "#imfolder_present = f'{base_dir}/final_experiment_pseudofoveated_no_ring/present/'\n",
    "#imfolder_absent = f'{base_dir}/final_experiment_pseudofoveated_no_ring/absent/'\n",
    "#stock TTM foveated\n",
    "imfolder_present = f'{base_dir}/final_experiment_TTMfoveated/'\n",
    "imfolder_absent = f'{base_dir}/final_experiment_TTMfoveated/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc4bb8f1-3073-427b-a29b-c05c097edaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Model Stuff\n",
    "def create_predictor(ecc,thresh):\n",
    "    #baseline model\n",
    "    cfg = get_cfg()\n",
    "    # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "    #cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    #cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    #cfg.merge_from_file('./detectron2/configs/quick_schedules/mask_rcnn_R_50_FPN_inference_acc_test.yaml')\n",
    "    cfg.merge_from_file('./detectron2/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml')\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = thresh #0.01  # set threshold for this model\n",
    "    #cfg.MODEL.RETINANET.SCORE_THRESH_TEST = thresh\n",
    "    # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "    #cfg.MODEL.WEIGHTS = '/home/gridsan/vdutell/.torch/iopath_cache/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl'\n",
    "    if(ecc=='-2'):\n",
    "        print('scratchtrain model')        \n",
    "        cfg.MODEL.WEIGHTS = f'{base_dir}/output_trainscratch/trainscratch_ecc100/model_final.pth'\n",
    "\n",
    "    elif(ecc=='-1'):\n",
    "        #baseline\n",
    "        print('baseline model')\n",
    "        cfg.MODEL.WEIGHTS = f'{base_dir}/detectron2/model_weights/R_50_FPN_3x/model_final_280758.pkl'\n",
    "    # elif(ecc=='100'):\n",
    "    #     cfg.MODEL.WEIGHTS = f'/home/gridsan/groups/RosenholtzLab/detection_repos/output/finetune_ecc{ecc}/model_final.pth'\n",
    "    else:\n",
    "        cfg.MODEL.WEIGHTS = f'{base_dir}/finetune_ecc{ecc}/model_final.pth'\n",
    "    #cfg.SOLVER.BASE_LR = 0.0001 #0.001 \n",
    "    #model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "    cfg.freeze()\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    return(cfg, predictor)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "427886fa-6766-43aa-9267-7508b5f947be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mong_lists(imname,ecc):\n",
    "    print(imname)\n",
    "    imname = imname.replace('.jpg','')\n",
    "    #uncomment here for pseudofoveated\n",
    "    #imfolder_present = f'{base_dir}/final_experiment_pseudofoveated_no_ring/present/'\n",
    "    #imfolder_absent = f'{base_dir}/final_experiment_pseudofoveated_no_ring/absent/'\n",
    "    imfolder_present = f'{base_dir}/final_experiment_TTMfoveated/present/'\n",
    "    imfolder_absent = f'{base_dir}/final_experiment_TTMfoveated/absent/'\n",
    "\n",
    "    present_mongs = []\n",
    "    absent_mongs = []\n",
    "    #present & absent\n",
    "    if ecc==0:\n",
    "        nmongs = 1\n",
    "    else:\n",
    "        nmongs = 10\n",
    "    \n",
    "    for i in range(nmongs):\n",
    "        try:\n",
    "            if(ecc==0):\n",
    "                pmong = cv2.imread(os.path.join(f'{base_dir}/final_experiment_multiple_mongrel_images_present/ecc0/\",f\"{imname}.jpg'))\n",
    "            else:\n",
    "                # pmong = cv2.imread(os.path.join(imfolder_present,f'ecc{ecc}/mongrel_{imname}_ecc_{ecc}_{i}.jpg'))\n",
    "                pmong = cv2.imread(os.path.join(imfolder_present,f'{ecc}/{imname}_{i}.png'))\n",
    "            present_mongs.append(pmong)\n",
    "        except:\n",
    "            print(os.path.join(imfolder_present,f'{ecc}/{imname}{i}.png'))\n",
    "        try:\n",
    "            if(ecc==0):\n",
    "                among = cv2.imread(os.path.join(f'{base_dir}/final_experiment_multiple_mongrel_images_absent/ecc0/\",f\"{imname}.png'))\n",
    "            else:                \n",
    "                among = cv2.imread(os.path.join(imfolder_absent,f'{ecc}/{imname}_{i}.png'))\n",
    "            #among = cv2.cvtColor(among, cv2.COLOR_BGR2RGB)\n",
    "            absent_mongs.append(among)\n",
    "        except:\n",
    "            print(os.path.join(imfolder_absent,f'{ecc}/{imname}_{i}.png'))\n",
    "\n",
    "        \n",
    "    return(present_mongs, absent_mongs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce4eeac9-8404-4aa9-964c-269dd1cf63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropbbxtoimage(bbx,imsz):\n",
    "    '''\n",
    "    If bounding box extends outside image size, crop it.\n",
    "    '''\n",
    "    x,y,w,h = bbx\n",
    "    #print(imsz)\n",
    "    imx,imy,_ = imsz\n",
    "    x=0 if x<0 else x #make sure x isn't negative\n",
    "    y=0 if y<0 else y #make sure y isn't negative\n",
    "    w=imx if w+x>imx else w #make sure width isn't larger than image\n",
    "    h=imy if h+y>imy else h #make sure height isn't taller than image\n",
    "    return([x,y,w,h])\n",
    "\n",
    "def bbx_xywhtoxyxy(bbx):\n",
    "    x,y,w,h = bbx\n",
    "    x2 = x + w\n",
    "    y2 = y + h\n",
    "    return([x,y,x2,y2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bda4d04-4e21-4e12-8912-8c0b7e616a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_match(model_predictions,\n",
    "                         ground_truth_object_id,\n",
    "                         ground_truth_bbx,\n",
    "                         padded_ground_truth_bbx,\n",
    "                         mong=None,\n",
    "                        enforce_category=True):\n",
    "    #find where ground truth object identity matches model class predictions\n",
    "    model_class_predictions = np.array(model_predictions['instances'].pred_classes.cpu())\n",
    "    \n",
    "    if(enforce_category):\n",
    "        prediction_matches = model_predictions['instances'][model_predictions['instances'].pred_classes==ground_truth_object_id]\n",
    "    else:\n",
    "        prediction_matches = model_predictions['instances']\n",
    "    #print(ground_truth_object_id)\n",
    "    #print(model_predictions['instances'].pred_classes)\n",
    "    #idx_matches = np.where(model_class_predictions == ground_truth_object_identity)[0]\n",
    "    #if doens't match anywhere prediction is zero\n",
    "    #print('number of predictions',len(prediction_matches))\n",
    "    if len(prediction_matches) == 0:\n",
    "        return(0.)\n",
    "    #otherwise find the best match\n",
    "    else:\n",
    "        \n",
    "        # #plotting for debugging\n",
    "        # if mong is not None:\n",
    "        #     fig,ax = plt.subplots()\n",
    "        #     ax.imshow(mong)\n",
    "        #     #groud truth\n",
    "        #     #print(ground_truth_bbx)\n",
    "        #     bbxplot = padded_ground_truth_bbx.tensor.cpu().numpy()[0]\n",
    "        #     bbxplot = [int(x) for x in bbxplot]\n",
    "        #     #print(bbxplot)\n",
    "        #     rect = patches.Rectangle((bbxplot[0],\n",
    "        #                              bbxplot[1]),\n",
    "        #                              bbxplot[2]-bbxplot[0],\n",
    "        #                              bbxplot[3]-bbxplot[1],\n",
    "        #                              linewidth=1, edgecolor='r',facecolor='none')\n",
    "        #     ax.add_patch(rect)\n",
    "\n",
    "        best_match_pred = 0.\n",
    "        #loop through matches and return the highest one that operlaps\n",
    "        for i in range(len(prediction_matches)):\n",
    "            pred = prediction_matches[i]\n",
    "            model_bbx_predictions = pred.pred_boxes\n",
    "            #print(model_bbx_predictions[0])\n",
    "            \n",
    "            # #plot prediction\n",
    "            # if mong is not None:\n",
    "            #     bbxplot = model_bbx_predictions.tensor.cpu().numpy()[0]\n",
    "            #     bbxplot = [int(x) for x in bbxplot]\n",
    "            #     rect = patches.Rectangle((bbxplot[0],\n",
    "            #                              bbxplot[1]),\n",
    "            #                              bbxplot[2]-bbxplot[0],\n",
    "            #                              bbxplot[3]-bbxplot[1],\n",
    "            #                              linewidth=1, edgecolor='b',facecolor='none')\n",
    "            #     ax.add_patch(rect)\n",
    "\n",
    "\n",
    "\n",
    "            #print('model bbx ',model_bbx_predictions)\n",
    "            #print('gt bbx ',ground_truth_bbx)\n",
    "            #iou = boxes.pairwise_iou(ground_truth_bbx, model_bbx_predictions)\n",
    "            ioa = boxes.pairwise_ioa(padded_ground_truth_bbx, model_bbx_predictions)\n",
    "            ioa = np.array(ioa.cpu().numpy())[0][0]\n",
    "            \n",
    "            #print('iou is',iou)\n",
    "            #condition 1\n",
    "            if ioa > 0.75:\n",
    "                #condition 2\n",
    "                areas_ratio = ground_truth_bbx.area()/model_bbx_predictions.area()\n",
    "                if (areas_ratio > 0.5) and (areas_ratio < 2.): #0.6/1.67 #0.75/1.33 #0.9/1.11 #0.5/2\n",
    "                    score = pred.scores.cpu().numpy()[0]\n",
    "                    #print(score)\n",
    "                    #if thats our best score, keep it\n",
    "                    if score > best_match_pred:\n",
    "                        #print('updating score to',score)\n",
    "                        best_match_pred = score\n",
    "        #print('best',best_match_pred)\n",
    "        if mong is not None:\n",
    "            plt.show()\n",
    "\n",
    "    #if more than one report the highest\n",
    "    return(best_match_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "105cf262-f41e-4d0f-97d3-107e7ca28acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_probabilities(pmong_prob, among_prob, nsamples):\n",
    "\n",
    "    if(pmong_prob==0. and among_prob==0.):\n",
    "        norm_among_prob = 0.5\n",
    "    elif(pmong_prob==0.):\n",
    "        norm_among_prob = 1.\n",
    "    elif(among_prob==0.):\n",
    "        norm_among_prob = 0.\n",
    "    else:\n",
    "        norm_among_prob = among_prob / (pmong_prob + among_prob)\n",
    "    #print(norm_among_prob)\n",
    "    samples = [np.random.rand() for i in range(nsamples)]\n",
    "    #if random [0,1] is greater than norm_among_prob then it's correct\n",
    "    #print(samples)\n",
    "    #print(norm_among_prob)\n",
    "    correct_preds = 1*np.greater(samples,norm_among_prob)\n",
    "    #print(correct_preds)\n",
    "    acc = np.mean(correct_preds)\n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb656a58-d628-4232-bd52-4515f956ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "def sample_probabilities_sdt(pmong_prob, among_prob, nsamples):\n",
    "    \n",
    "    #probability can't be exacly zero\n",
    "    pmong_prob = pmong_prob if pmong_prob>=1e-5 else 1e-5\n",
    "    among_prob = among_prob if among_prob>=1e-5 else 1e-5\n",
    "\n",
    "    #calcluate z scores\n",
    "    among_z = norm.ppf(q=(among_prob)) #ppd takes lower tail probability, among_prob is upper.\n",
    "    pmong_z = norm.ppf(q=(pmong_prob)) #ppd takes lower tail probability, pmong_prob is upper.\n",
    "    \n",
    "    d_prime = pmong_z - among_z #d prime is difference beween the two\n",
    "    \n",
    "    #print('among_z: ',among_z)\n",
    "    #print('pmong_z: ',pmong_z)\n",
    "    #print('d_prime: ',d_prime)\n",
    "    \n",
    "    among_dist_samples = np.random.normal(loc=0,size=nsamples) #sample from normal for among dist\n",
    "    pmong_dist_samples = np.random.normal(loc=d_prime,size=nsamples) #sample from normal for pmong dist\n",
    "    \n",
    "    #print('absent samples: ',among_dist_samples)\n",
    "    #print('present samples: ',pmong_dist_samples)\n",
    "    correct = 1*np.greater(pmong_dist_samples, among_dist_samples) #check if pmong was higher\n",
    "    acc = np.mean(correct)\n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a5006c-47a3-4784-9cea-80417758f9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scratchtrain model\n",
      "[09/16 12:55:20 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /home/gridsan/groups/RosenholtzLab/detection_repos/output_trainscratch/trainscratch_ecc100/model_final.pth ...\n",
      "000000009590.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/llgrid/pkg/anaconda/anaconda3-2022b/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for model -2 for 000000009590.jpg at ecc 0 is 1.0\n",
      "000000009590.jpg\n",
      "accuracy for model -2 for 000000009590.jpg at ecc 80 is 1.0\n",
      "000000009590.jpg\n",
      "accuracy for model -2 for 000000009590.jpg at ecc 160 is 1.0\n",
      "000000009590.jpg\n",
      "accuracy for model -2 for 000000009590.jpg at ecc 240 is 0.465\n",
      "000000009590.jpg\n",
      "accuracy for model -2 for 000000009590.jpg at ecc 320 is 0.65\n",
      "000000009769.jpg\n",
      "accuracy for model -2 for 000000009769.jpg at ecc 0 is 1.0\n",
      "000000009769.jpg\n",
      "accuracy for model -2 for 000000009769.jpg at ecc 80 is 0.9\n",
      "000000009769.jpg\n",
      "accuracy for model -2 for 000000009769.jpg at ecc 160 is 0.7\n",
      "000000009769.jpg\n",
      "accuracy for model -2 for 000000009769.jpg at ecc 240 is 0.5\n",
      "000000009769.jpg\n",
      "accuracy for model -2 for 000000009769.jpg at ecc 320 is 0.5\n",
      "000000011197.jpg\n",
      "accuracy for model -2 for 000000011197.jpg at ecc 0 is 1.0\n",
      "000000011197.jpg\n",
      "accuracy for model -2 for 000000011197.jpg at ecc 80 is 1.0\n",
      "000000011197.jpg\n",
      "accuracy for model -2 for 000000011197.jpg at ecc 160 is 1.0\n",
      "000000011197.jpg\n",
      "accuracy for model -2 for 000000011197.jpg at ecc 240 is 0.92\n",
      "000000011197.jpg\n",
      "accuracy for model -2 for 000000011197.jpg at ecc 320 is 0.58\n",
      "000000016439.jpg\n",
      "accuracy for model -2 for 000000016439.jpg at ecc 0 is 1.0\n",
      "000000016439.jpg\n",
      "accuracy for model -2 for 000000016439.jpg at ecc 80 is 1.0\n",
      "000000016439.jpg\n",
      "accuracy for model -2 for 000000016439.jpg at ecc 160 is 0.95\n",
      "000000016439.jpg\n",
      "accuracy for model -2 for 000000016439.jpg at ecc 240 is 0.85\n",
      "000000016439.jpg\n",
      "accuracy for model -2 for 000000016439.jpg at ecc 320 is 0.6\n",
      "000000018150.jpg\n",
      "accuracy for model -2 for 000000018150.jpg at ecc 0 is 1.0\n",
      "000000018150.jpg\n",
      "accuracy for model -2 for 000000018150.jpg at ecc 80 is 1.0\n",
      "000000018150.jpg\n",
      "accuracy for model -2 for 000000018150.jpg at ecc 160 is 0.5\n",
      "000000018150.jpg\n",
      "accuracy for model -2 for 000000018150.jpg at ecc 240 is 0.5\n",
      "000000018150.jpg\n",
      "accuracy for model -2 for 000000018150.jpg at ecc 320 is 0.5\n",
      "000000018380.jpg\n",
      "accuracy for model -2 for 000000018380.jpg at ecc 0 is 1.0\n",
      "000000018380.jpg\n",
      "accuracy for model -2 for 000000018380.jpg at ecc 80 is 0.45\n",
      "000000018380.jpg\n",
      "accuracy for model -2 for 000000018380.jpg at ecc 160 is 0.65\n",
      "000000018380.jpg\n",
      "accuracy for model -2 for 000000018380.jpg at ecc 240 is 0.5\n",
      "000000018380.jpg\n",
      "accuracy for model -2 for 000000018380.jpg at ecc 320 is 0.5\n",
      "000000019042.jpg\n",
      "accuracy for model -2 for 000000019042.jpg at ecc 0 is 1.0\n",
      "000000019042.jpg\n",
      "accuracy for model -2 for 000000019042.jpg at ecc 80 is 1.0\n",
      "000000019042.jpg\n",
      "accuracy for model -2 for 000000019042.jpg at ecc 160 is 0.8\n",
      "000000019042.jpg\n",
      "accuracy for model -2 for 000000019042.jpg at ecc 240 is 0.55\n",
      "000000019042.jpg\n",
      "accuracy for model -2 for 000000019042.jpg at ecc 320 is 0.6\n",
      "000000061268.jpg\n",
      "accuracy for model -2 for 000000061268.jpg at ecc 0 is 1.0\n",
      "000000061268.jpg\n",
      "accuracy for model -2 for 000000061268.jpg at ecc 80 is 1.0\n",
      "000000061268.jpg\n",
      "accuracy for model -2 for 000000061268.jpg at ecc 160 is 0.9\n",
      "000000061268.jpg\n",
      "accuracy for model -2 for 000000061268.jpg at ecc 240 is 0.66\n",
      "000000061268.jpg\n",
      "accuracy for model -2 for 000000061268.jpg at ecc 320 is 0.45\n",
      "000000063602.jpg\n",
      "accuracy for model -2 for 000000063602.jpg at ecc 0 is 1.0\n",
      "000000063602.jpg\n",
      "accuracy for model -2 for 000000063602.jpg at ecc 80 is 1.0\n",
      "000000063602.jpg\n",
      "accuracy for model -2 for 000000063602.jpg at ecc 160 is 0.63\n",
      "000000063602.jpg\n",
      "accuracy for model -2 for 000000063602.jpg at ecc 240 is 0.46\n",
      "000000063602.jpg\n",
      "accuracy for model -2 for 000000063602.jpg at ecc 320 is 0.5\n",
      "000000067616.jpg\n",
      "accuracy for model -2 for 000000067616.jpg at ecc 0 is 1.0\n",
      "000000067616.jpg\n",
      "accuracy for model -2 for 000000067616.jpg at ecc 80 is 1.0\n",
      "000000067616.jpg\n",
      "accuracy for model -2 for 000000067616.jpg at ecc 160 is 0.99\n",
      "000000067616.jpg\n",
      "accuracy for model -2 for 000000067616.jpg at ecc 240 is 0.62\n",
      "000000067616.jpg\n",
      "accuracy for model -2 for 000000067616.jpg at ecc 320 is 0.66\n",
      "000000119445.jpg\n",
      "accuracy for model -2 for 000000119445.jpg at ecc 0 is 1.0\n",
      "000000119445.jpg\n",
      "accuracy for model -2 for 000000119445.jpg at ecc 80 is 0.9\n",
      "000000119445.jpg\n",
      "accuracy for model -2 for 000000119445.jpg at ecc 160 is 0.705\n",
      "000000119445.jpg\n",
      "accuracy for model -2 for 000000119445.jpg at ecc 240 is 0.51\n",
      "000000119445.jpg\n",
      "accuracy for model -2 for 000000119445.jpg at ecc 320 is 0.55\n",
      "000000119516.jpg\n",
      "accuracy for model -2 for 000000119516.jpg at ecc 0 is 1.0\n",
      "000000119516.jpg\n",
      "accuracy for model -2 for 000000119516.jpg at ecc 80 is 1.0\n",
      "000000119516.jpg\n",
      "accuracy for model -2 for 000000119516.jpg at ecc 160 is 0.34\n",
      "000000119516.jpg\n",
      "accuracy for model -2 for 000000119516.jpg at ecc 240 is 0.55\n",
      "000000119516.jpg\n",
      "accuracy for model -2 for 000000119516.jpg at ecc 320 is 0.37\n",
      "000000186422.jpg\n",
      "accuracy for model -2 for 000000186422.jpg at ecc 0 is 1.0\n",
      "000000186422.jpg\n",
      "accuracy for model -2 for 000000186422.jpg at ecc 80 is 1.0\n",
      "000000186422.jpg\n",
      "accuracy for model -2 for 000000186422.jpg at ecc 160 is 0.7\n",
      "000000186422.jpg\n",
      "accuracy for model -2 for 000000186422.jpg at ecc 240 is 0.65\n",
      "000000186422.jpg\n",
      "accuracy for model -2 for 000000186422.jpg at ecc 320 is 0.5\n",
      "000000203864.jpg\n",
      "accuracy for model -2 for 000000203864.jpg at ecc 0 is 1.0\n",
      "000000203864.jpg\n",
      "accuracy for model -2 for 000000203864.jpg at ecc 80 is 0.95\n",
      "000000203864.jpg\n",
      "accuracy for model -2 for 000000203864.jpg at ecc 160 is 0.9\n",
      "000000203864.jpg\n",
      "accuracy for model -2 for 000000203864.jpg at ecc 240 is 0.6\n",
      "000000203864.jpg\n",
      "accuracy for model -2 for 000000203864.jpg at ecc 320 is 0.5\n",
      "000000209530.jpg\n",
      "accuracy for model -2 for 000000209530.jpg at ecc 0 is 1.0\n",
      "000000209530.jpg\n",
      "accuracy for model -2 for 000000209530.jpg at ecc 80 is 1.0\n",
      "000000209530.jpg\n",
      "accuracy for model -2 for 000000209530.jpg at ecc 160 is 0.5\n",
      "000000209530.jpg\n",
      "accuracy for model -2 for 000000209530.jpg at ecc 240 is 0.5\n",
      "000000209530.jpg\n",
      "accuracy for model -2 for 000000209530.jpg at ecc 320 is 0.5\n",
      "000000222299.jpg\n",
      "accuracy for model -2 for 000000222299.jpg at ecc 0 is 1.0\n",
      "000000222299.jpg\n",
      "accuracy for model -2 for 000000222299.jpg at ecc 80 is 1.0\n",
      "000000222299.jpg\n",
      "accuracy for model -2 for 000000222299.jpg at ecc 160 is 0.9\n",
      "000000222299.jpg\n",
      "accuracy for model -2 for 000000222299.jpg at ecc 240 is 0.5\n",
      "000000222299.jpg\n",
      "accuracy for model -2 for 000000222299.jpg at ecc 320 is 0.5\n",
      "000000226417.jpg\n",
      "accuracy for model -2 for 000000226417.jpg at ecc 0 is 1.0\n",
      "000000226417.jpg\n",
      "accuracy for model -2 for 000000226417.jpg at ecc 80 is 1.0\n",
      "000000226417.jpg\n",
      "accuracy for model -2 for 000000226417.jpg at ecc 160 is 0.75\n",
      "000000226417.jpg\n",
      "accuracy for model -2 for 000000226417.jpg at ecc 240 is 0.55\n",
      "000000226417.jpg\n",
      "accuracy for model -2 for 000000226417.jpg at ecc 320 is 0.5\n",
      "000000255165.jpg\n",
      "accuracy for model -2 for 000000255165.jpg at ecc 0 is 1.0\n",
      "000000255165.jpg\n",
      "accuracy for model -2 for 000000255165.jpg at ecc 80 is 1.0\n",
      "000000255165.jpg\n",
      "accuracy for model -2 for 000000255165.jpg at ecc 160 is 0.95\n",
      "000000255165.jpg\n",
      "accuracy for model -2 for 000000255165.jpg at ecc 240 is 0.4\n",
      "000000255165.jpg\n",
      "accuracy for model -2 for 000000255165.jpg at ecc 320 is 0.5\n",
      "000000281409.jpg\n",
      "accuracy for model -2 for 000000281409.jpg at ecc 0 is 1.0\n",
      "000000281409.jpg\n",
      "accuracy for model -2 for 000000281409.jpg at ecc 80 is 1.0\n",
      "000000281409.jpg\n",
      "accuracy for model -2 for 000000281409.jpg at ecc 160 is 1.0\n",
      "000000281409.jpg\n",
      "accuracy for model -2 for 000000281409.jpg at ecc 240 is 0.9\n",
      "000000281409.jpg\n",
      "accuracy for model -2 for 000000281409.jpg at ecc 320 is 0.615\n",
      "000000311002.jpg\n",
      "accuracy for model -2 for 000000311002.jpg at ecc 0 is 1.0\n",
      "000000311002.jpg\n",
      "accuracy for model -2 for 000000311002.jpg at ecc 80 is 1.0\n",
      "000000311002.jpg\n",
      "accuracy for model -2 for 000000311002.jpg at ecc 160 is 0.5\n",
      "000000311002.jpg\n",
      "accuracy for model -2 for 000000311002.jpg at ecc 240 is 0.5\n",
      "000000311002.jpg\n",
      "accuracy for model -2 for 000000311002.jpg at ecc 320 is 0.5\n",
      "000000322163.jpg\n",
      "accuracy for model -2 for 000000322163.jpg at ecc 0 is 1.0\n",
      "000000322163.jpg\n",
      "accuracy for model -2 for 000000322163.jpg at ecc 80 is 1.0\n",
      "000000322163.jpg\n",
      "accuracy for model -2 for 000000322163.jpg at ecc 160 is 0.85\n",
      "000000322163.jpg\n",
      "accuracy for model -2 for 000000322163.jpg at ecc 240 is 0.55\n",
      "000000322163.jpg\n",
      "accuracy for model -2 for 000000322163.jpg at ecc 320 is 0.55\n",
      "000000484351.jpg\n",
      "accuracy for model -2 for 000000484351.jpg at ecc 0 is 1.0\n",
      "000000484351.jpg\n",
      "accuracy for model -2 for 000000484351.jpg at ecc 80 is 1.0\n",
      "000000484351.jpg\n",
      "accuracy for model -2 for 000000484351.jpg at ecc 160 is 0.5\n",
      "000000484351.jpg\n",
      "accuracy for model -2 for 000000484351.jpg at ecc 240 is 0.5\n",
      "000000484351.jpg\n",
      "accuracy for model -2 for 000000484351.jpg at ecc 320 is 0.5\n",
      "000000491008.jpg\n",
      "accuracy for model -2 for 000000491008.jpg at ecc 0 is 1.0\n",
      "000000491008.jpg\n",
      "accuracy for model -2 for 000000491008.jpg at ecc 80 is 1.0\n",
      "000000491008.jpg\n",
      "accuracy for model -2 for 000000491008.jpg at ecc 160 is 1.0\n",
      "000000491008.jpg\n",
      "accuracy for model -2 for 000000491008.jpg at ecc 240 is 0.56\n",
      "000000491008.jpg\n",
      "accuracy for model -2 for 000000491008.jpg at ecc 320 is 0.45\n",
      "000000509258.jpg\n",
      "accuracy for model -2 for 000000509258.jpg at ecc 0 is 1.0\n",
      "000000509258.jpg\n",
      "accuracy for model -2 for 000000509258.jpg at ecc 80 is 1.0\n",
      "000000509258.jpg\n",
      "accuracy for model -2 for 000000509258.jpg at ecc 160 is 0.715\n",
      "000000509258.jpg\n",
      "accuracy for model -2 for 000000509258.jpg at ecc 240 is 0.5\n",
      "000000509258.jpg\n",
      "accuracy for model -2 for 000000509258.jpg at ecc 320 is 0.5\n",
      "000000529148.jpg\n",
      "accuracy for model -2 for 000000529148.jpg at ecc 0 is 1.0\n",
      "000000529148.jpg\n",
      "accuracy for model -2 for 000000529148.jpg at ecc 80 is 1.0\n",
      "000000529148.jpg\n",
      "accuracy for model -2 for 000000529148.jpg at ecc 160 is 0.85\n",
      "000000529148.jpg\n",
      "accuracy for model -2 for 000000529148.jpg at ecc 240 is 0.85\n",
      "000000529148.jpg\n",
      "accuracy for model -2 for 000000529148.jpg at ecc 320 is 0.55\n",
      "000000545100.jpg\n",
      "accuracy for model -2 for 000000545100.jpg at ecc 0 is 1.0\n",
      "000000545100.jpg\n",
      "accuracy for model -2 for 000000545100.jpg at ecc 80 is 1.0\n",
      "000000545100.jpg\n",
      "accuracy for model -2 for 000000545100.jpg at ecc 160 is 0.85\n",
      "000000545100.jpg\n",
      "accuracy for model -2 for 000000545100.jpg at ecc 240 is 0.5\n",
      "000000545100.jpg\n",
      "accuracy for model -2 for 000000545100.jpg at ecc 320 is 0.65\n",
      "[09/16 13:18:57 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /home/gridsan/groups/RosenholtzLab/detection_repos/output/finetune_ecc100/model_final.pth ...\n",
      "000000009590.jpg\n",
      "accuracy for model 100 for 000000009590.jpg at ecc 0 is 1.0\n",
      "000000009590.jpg\n",
      "accuracy for model 100 for 000000009590.jpg at ecc 80 is 1.0\n",
      "000000009590.jpg\n",
      "accuracy for model 100 for 000000009590.jpg at ecc 160 is 0.99\n",
      "000000009590.jpg\n",
      "accuracy for model 100 for 000000009590.jpg at ecc 240 is 0.43\n",
      "000000009590.jpg\n",
      "accuracy for model 100 for 000000009590.jpg at ecc 320 is 0.65\n",
      "000000009769.jpg\n",
      "accuracy for model 100 for 000000009769.jpg at ecc 0 is 1.0\n",
      "000000009769.jpg\n",
      "accuracy for model 100 for 000000009769.jpg at ecc 80 is 0.9\n",
      "000000009769.jpg\n",
      "accuracy for model 100 for 000000009769.jpg at ecc 160 is 0.7\n",
      "000000009769.jpg\n",
      "accuracy for model 100 for 000000009769.jpg at ecc 240 is 0.5\n",
      "000000009769.jpg\n",
      "accuracy for model 100 for 000000009769.jpg at ecc 320 is 0.5\n",
      "000000011197.jpg\n",
      "accuracy for model 100 for 000000011197.jpg at ecc 0 is 1.0\n",
      "000000011197.jpg\n",
      "accuracy for model 100 for 000000011197.jpg at ecc 80 is 1.0\n",
      "000000011197.jpg\n",
      "accuracy for model 100 for 000000011197.jpg at ecc 160 is 1.0\n",
      "000000011197.jpg\n",
      "accuracy for model 100 for 000000011197.jpg at ecc 240 is 0.95\n",
      "000000011197.jpg\n",
      "accuracy for model 100 for 000000011197.jpg at ecc 320 is 0.45\n",
      "000000016439.jpg\n",
      "accuracy for model 100 for 000000016439.jpg at ecc 0 is 1.0\n",
      "000000016439.jpg\n",
      "accuracy for model 100 for 000000016439.jpg at ecc 80 is 1.0\n",
      "000000016439.jpg\n",
      "accuracy for model 100 for 000000016439.jpg at ecc 160 is 0.9\n",
      "000000016439.jpg\n",
      "accuracy for model 100 for 000000016439.jpg at ecc 240 is 0.55\n",
      "000000016439.jpg\n",
      "accuracy for model 100 for 000000016439.jpg at ecc 320 is 0.5\n",
      "000000018150.jpg\n",
      "accuracy for model 100 for 000000018150.jpg at ecc 0 is 1.0\n",
      "000000018150.jpg\n",
      "accuracy for model 100 for 000000018150.jpg at ecc 80 is 1.0\n",
      "000000018150.jpg\n",
      "accuracy for model 100 for 000000018150.jpg at ecc 160 is 0.5\n",
      "000000018150.jpg\n",
      "accuracy for model 100 for 000000018150.jpg at ecc 240 is 0.5\n",
      "000000018150.jpg\n",
      "accuracy for model 100 for 000000018150.jpg at ecc 320 is 0.5\n",
      "000000018380.jpg\n",
      "accuracy for model 100 for 000000018380.jpg at ecc 0 is 0.0\n",
      "000000018380.jpg\n",
      "accuracy for model 100 for 000000018380.jpg at ecc 80 is 0.69\n",
      "000000018380.jpg\n",
      "accuracy for model 100 for 000000018380.jpg at ecc 160 is 0.55\n",
      "000000018380.jpg\n",
      "accuracy for model 100 for 000000018380.jpg at ecc 240 is 0.45\n",
      "000000018380.jpg\n",
      "accuracy for model 100 for 000000018380.jpg at ecc 320 is 0.5\n",
      "000000019042.jpg\n",
      "accuracy for model 100 for 000000019042.jpg at ecc 0 is 1.0\n",
      "000000019042.jpg\n",
      "accuracy for model 100 for 000000019042.jpg at ecc 80 is 1.0\n",
      "000000019042.jpg\n",
      "accuracy for model 100 for 000000019042.jpg at ecc 160 is 0.8\n",
      "000000019042.jpg\n",
      "accuracy for model 100 for 000000019042.jpg at ecc 240 is 0.6\n",
      "000000019042.jpg\n",
      "accuracy for model 100 for 000000019042.jpg at ecc 320 is 0.55\n",
      "000000061268.jpg\n",
      "accuracy for model 100 for 000000061268.jpg at ecc 0 is 1.0\n",
      "000000061268.jpg\n",
      "accuracy for model 100 for 000000061268.jpg at ecc 80 is 0.95\n",
      "000000061268.jpg\n",
      "accuracy for model 100 for 000000061268.jpg at ecc 160 is 0.8\n",
      "000000061268.jpg\n",
      "accuracy for model 100 for 000000061268.jpg at ecc 240 is 0.75\n",
      "000000061268.jpg\n",
      "accuracy for model 100 for 000000061268.jpg at ecc 320 is 0.55\n",
      "000000063602.jpg\n",
      "accuracy for model 100 for 000000063602.jpg at ecc 0 is 1.0\n",
      "000000063602.jpg\n",
      "accuracy for model 100 for 000000063602.jpg at ecc 80 is 1.0\n",
      "000000063602.jpg\n",
      "accuracy for model 100 for 000000063602.jpg at ecc 160 is 0.675\n",
      "000000063602.jpg\n",
      "accuracy for model 100 for 000000119445.jpg at ecc 320 is 0.505\n",
      "000000119516.jpg\n",
      "accuracy for model 100 for 000000119516.jpg at ecc 0 is 1.0\n",
      "000000119516.jpg\n",
      "accuracy for model 100 for 000000119516.jpg at ecc 80 is 1.0\n",
      "000000119516.jpg\n",
      "accuracy for model 100 for 000000119516.jpg at ecc 160 is 0.45\n",
      "000000119516.jpg\n",
      "accuracy for model 100 for 000000119516.jpg at ecc 240 is 0.5\n",
      "000000119516.jpg\n",
      "accuracy for model 100 for 000000119516.jpg at ecc 320 is 0.34\n",
      "000000186422.jpg\n",
      "accuracy for model 100 for 000000186422.jpg at ecc 0 is 1.0\n",
      "000000186422.jpg\n",
      "accuracy for model 100 for 000000186422.jpg at ecc 80 is 1.0\n",
      "000000186422.jpg\n",
      "accuracy for model 100 for 000000186422.jpg at ecc 160 is 0.7\n",
      "000000186422.jpg\n",
      "accuracy for model 100 for 000000186422.jpg at ecc 240 is 0.65\n",
      "000000186422.jpg\n",
      "accuracy for model 100 for 000000186422.jpg at ecc 320 is 0.5\n",
      "000000203864.jpg\n",
      "accuracy for model 100 for 000000203864.jpg at ecc 0 is 1.0\n",
      "000000203864.jpg\n",
      "accuracy for model 100 for 000000203864.jpg at ecc 80 is 1.0\n",
      "000000203864.jpg\n",
      "accuracy for model 100 for 000000203864.jpg at ecc 160 is 0.9\n",
      "000000203864.jpg\n",
      "accuracy for model 100 for 000000203864.jpg at ecc 240 is 0.55\n",
      "000000203864.jpg\n",
      "accuracy for model 100 for 000000203864.jpg at ecc 320 is 0.5\n",
      "000000209530.jpg\n",
      "accuracy for model 100 for 000000209530.jpg at ecc 0 is 1.0\n",
      "000000209530.jpg\n",
      "accuracy for model 100 for 000000209530.jpg at ecc 80 is 0.5\n",
      "000000209530.jpg\n",
      "accuracy for model 100 for 000000209530.jpg at ecc 160 is 0.5\n",
      "000000209530.jpg\n",
      "accuracy for model 100 for 000000209530.jpg at ecc 240 is 0.5\n",
      "000000209530.jpg\n",
      "accuracy for model 100 for 000000209530.jpg at ecc 320 is 0.5\n",
      "000000222299.jpg\n",
      "accuracy for model 100 for 000000222299.jpg at ecc 0 is 1.0\n",
      "000000222299.jpg\n",
      "accuracy for model 100 for 000000222299.jpg at ecc 80 is 1.0\n",
      "000000222299.jpg\n",
      "accuracy for model 100 for 000000222299.jpg at ecc 160 is 0.8\n",
      "000000222299.jpg\n",
      "accuracy for model 100 for 000000222299.jpg at ecc 240 is 0.5\n",
      "000000222299.jpg\n",
      "accuracy for model 100 for 000000222299.jpg at ecc 320 is 0.5\n",
      "000000226417.jpg\n",
      "accuracy for model 100 for 000000226417.jpg at ecc 0 is 1.0\n",
      "000000226417.jpg\n",
      "accuracy for model 100 for 000000226417.jpg at ecc 80 is 1.0\n",
      "000000226417.jpg\n",
      "accuracy for model 100 for 000000226417.jpg at ecc 160 is 0.815\n",
      "000000226417.jpg\n",
      "accuracy for model 100 for 000000226417.jpg at ecc 240 is 0.395\n",
      "000000226417.jpg\n",
      "accuracy for model 100 for 000000226417.jpg at ecc 320 is 0.55\n",
      "000000255165.jpg\n",
      "accuracy for model 100 for 000000255165.jpg at ecc 0 is 1.0\n",
      "000000255165.jpg\n",
      "accuracy for model 100 for 000000255165.jpg at ecc 80 is 1.0\n",
      "000000255165.jpg\n",
      "accuracy for model 100 for 000000255165.jpg at ecc 160 is 0.815\n",
      "000000255165.jpg\n",
      "accuracy for model 100 for 000000255165.jpg at ecc 240 is 0.6\n",
      "000000255165.jpg\n",
      "accuracy for model 100 for 000000255165.jpg at ecc 320 is 0.5\n",
      "000000281409.jpg\n",
      "accuracy for model 100 for 000000281409.jpg at ecc 0 is 1.0\n",
      "000000281409.jpg\n",
      "accuracy for model 100 for 000000281409.jpg at ecc 80 is 1.0\n",
      "000000281409.jpg\n",
      "accuracy for model 100 for 000000281409.jpg at ecc 160 is 1.0\n",
      "000000281409.jpg\n",
      "accuracy for model 100 for 000000281409.jpg at ecc 240 is 0.9\n",
      "000000281409.jpg\n",
      "accuracy for model 100 for 000000281409.jpg at ecc 320 is 0.595\n",
      "000000311002.jpg\n",
      "accuracy for model 100 for 000000311002.jpg at ecc 0 is 1.0\n",
      "000000311002.jpg\n",
      "accuracy for model 100 for 000000311002.jpg at ecc 80 is 0.85\n",
      "000000311002.jpg\n",
      "accuracy for model 100 for 000000311002.jpg at ecc 160 is 0.5\n",
      "000000311002.jpg\n"
     ]
    }
   ],
   "source": [
    "#model_names = ['-1','0','-2','100','5','10','15']\n",
    "model_names = ['0','5','10','15','20','-1','-2','100','101']\n",
    "model_names = ['-2','100','101']\n",
    "nsamples = 1000\n",
    "pred_thresh = 0.1\n",
    "category_match_bool = False\n",
    "\n",
    "accuracies = {}\n",
    "for mi, model_name in enumerate(model_names):\n",
    "    accuracies[model_name] = {}\n",
    "    #create predictor\n",
    "    cfg, predictor = create_predictor(model_name,thresh=pred_thresh)\n",
    "    for im in imlist:\n",
    "        #make a dictionary\n",
    "        accuracies[model_name][im] = {}\n",
    "        for ecci, ecc in enumerate(eccs_px):\n",
    "            accuracies[model_name][im][ecc] = {}\n",
    "            present_mongs, absent_mongs = gen_mong_lists(im,ecc)\n",
    "            #store accuracy array for pairs of this mongrel + eccentricity combo\n",
    "            im_ecc_accuracies = []\n",
    "\n",
    "            ###### Run Inference on model (in parallel)\n",
    "            #pmong_model_predictions_batch = predictor(torch.from_numpy(np.array(present_mongs)))\n",
    "            #among_model_predictions_batch = predictor(torch.from_numpy(np.array(absent_mongs)))\n",
    "            \n",
    "            #loop through pairs            \n",
    "            #for i in range(len(pmong_model_predictions)):\n",
    "            #    for j in range(len(among_model_predictions)):\n",
    "            #print(present_mongs.type)\n",
    "            for i in range(len(present_mongs)):\n",
    "                for j in range(len(absent_mongs)):\n",
    "                    #print(i,j)\n",
    "                    pmong = present_mongs[i]\n",
    "                    among = absent_mongs[j]\n",
    "                    ###### Run Inference on model (in serial)\n",
    "                    pmong_model_predictions = predictor(pmong)\n",
    "                    among_model_predictions = predictor(among)\n",
    "                    \n",
    "                    ###### Get Inference (in parallel)\n",
    "                    #pmong_model_predictions = pmong_model_predictions_batch[i]\n",
    "                    #among_model_predictions = among_model_predictions_batch[j]\n",
    "\n",
    "                    ##### Get Ground Truth\n",
    "                    #get ground truth bounding box\n",
    "                    ground_truth_bbx = [bbx_list[bbx_list['image_name']==im]['bbx_x_16'].item(),\n",
    "                                       bbx_list[bbx_list['image_name']==im]['bbx_y_16'].item(),\n",
    "                                       bbx_list[bbx_list['image_name']==im]['bbx_w_16'].item(),\n",
    "                                       bbx_list[bbx_list['image_name']==im]['bbx_h_16'].item()]\n",
    "                    padded_ground_truth_bbx = [sum(x) for x in zip(ground_truth_bbx, [-ecc//4, #move x half a pooling region to left\n",
    "                                                                                  -ecc//4, #move y half a pooling region to right\n",
    "                                                                                   ecc//2, #increase width by full pooling region\n",
    "                                                                                   ecc//2] #increase height by full pooling region\n",
    "                                       )]\n",
    "                    #crop bbx if it extends beyond edge of image\n",
    "                    padded_ground_truth_bbx = cropbbxtoimage(ground_truth_bbx,pmong.shape)\n",
    "                    #print(print('bbx before',ground_truth_bbx))\n",
    "                    padded_ground_truth_bbx = bbx_xywhtoxyxy(padded_ground_truth_bbx)\n",
    "                    #print(print('bbx after',ground_truth_bbx))\n",
    "                    #convert to detectron2 Boxes for IOU calculation\n",
    "                    padded_ground_truth_bbx = boxes.Boxes(torch.unsqueeze(torch.Tensor(padded_ground_truth_bbx),0).to(device))\n",
    "\n",
    "                    #convert original ground truth bounding box also\n",
    "                    ground_truth_bbx = bbx_xywhtoxyxy(ground_truth_bbx)\n",
    "                    ground_truth_bbx = boxes.Boxes(torch.unsqueeze(torch.Tensor(ground_truth_bbx),0).to(device))\n",
    "                    \n",
    "                    #ground truth object category & ID\n",
    "                    ground_truth_object_name = bbx_list[bbx_list['image_name']==im]['object_name'].item()\n",
    "                    ground_truth_object_id = label_converter_dict[ground_truth_object_name]\n",
    "\n",
    "                    ###### Compare Ground Truth and Inference Result\n",
    "                    pmong_prob = get_prediction_match(pmong_model_predictions,\n",
    "                                                      ground_truth_object_id,\n",
    "                                                      ground_truth_bbx,\n",
    "                                                      padded_ground_truth_bbx,\n",
    "                                                     enforce_category=category_match_bool)\n",
    "                    among_prob = get_prediction_match(among_model_predictions,\n",
    "                                                      ground_truth_object_id,\n",
    "                                                      ground_truth_bbx,\n",
    "                                                      padded_ground_truth_bbx,\n",
    "                                                     enforce_category=category_match_bool)\n",
    "                    #print(pmong_prob, among_prob)\n",
    "                    # v = Visualizer(among[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "                    # out = v.draw_instance_predictions(among_model_predictions[\"instances\"].to(\"cpu\"))\n",
    "                    # img = out.get_image()[:, :, ::-1]\n",
    "                    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    # plt.imshow(img)\n",
    "                    # plt.axis('off')\n",
    "                    # plt.show()\n",
    "\n",
    "                    ####### Do Sampling for 2AFC Experiment\n",
    "                    #sample from normalized probability\n",
    "                    # acc = sample_probabilities_sdt(pmong_prob, among_prob, nsamples)\n",
    "                    if pmong_prob == among_prob:\n",
    "                        acc = 0.5\n",
    "                    else:\n",
    "                        acc = float(pmong_prob > among_prob)\n",
    "                    im_ecc_accuracies.append(acc)\n",
    "            im_ecc_accuracies = np.array(im_ecc_accuracies)\n",
    "            if(ecc==0):\n",
    "                mean = im_ecc_accuracies[0]\n",
    "                std = np.nan\n",
    "            else:\n",
    "                mean = np.nanmean(im_ecc_accuracies)\n",
    "                std = np.nanstd(im_ecc_accuracies)\n",
    "            accuracies[model_name][im][ecc] = {'mean': mean,\n",
    "                                               'std': std,\n",
    "                                               'raw': im_ecc_accuracies}\n",
    "            mn = accuracies[model_name][im][ecc]['mean']\n",
    "            print(f'accuracy for model {model_name} for {im} at ecc {ecc} is {mn}')\n",
    "            #print(accuracies)\n",
    "    pkl_file = f'{base_dir}/yes_threshold_TTM_results/machine_psychophysics_accuracies_full_sdt_model{model_name}_stockfoveated.pickle'\n",
    "    file = open(pkl_file,'wb')\n",
    "    pickle.dump(accuracies[model_name],file)\n",
    "    file.close()\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de1e71a-cc0e-4018-a34f-8ac784c9b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pkl_file = f'{base_dir}/yes_threshold_TTM_results/machine_psychophysics_accuracies_full_sdt_stockfoveated.pickle'\n",
    "file = open(pkl_file,'wb')\n",
    "pickle.dump(accuracies,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06163096-1dad-41e5-bb47-7fe69c8c7cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
