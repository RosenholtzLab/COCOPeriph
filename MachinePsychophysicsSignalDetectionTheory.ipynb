{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90627f27-ca3b-4172-8dd8-e64766d25b1e",
   "metadata": {},
   "source": [
    "# Run a Machine Psychophysics Experiment Signal Detection Theory -- no threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec217ac-6ccc-4712-9fdb-518503c73050",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load requirements\n",
    "import sys, os, distutils.core\n",
    "import torch, detectron2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "import detectron2.structures.boxes as boxes\n",
    "\n",
    "#import coco json ID to label conversion\n",
    "import coco_object_categories\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pickle\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "######CHANGE THIS BASED ON YOUR FILE LOCATIONS!!!\n",
    "base_dir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a161ed2f-92a6-4b49-9a8a-097363a7cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the normal nnotation file in coco has 90 categories for some unknown reason. Use the real ones from this text file.\n",
    "anns_file = './train_finetune/coco80annotations.txt'\n",
    "with open(anns_file) as f:\n",
    "    anns = [line.replace('\\n','') for line in f.readlines()]\n",
    "\n",
    "label_converter_dict = {}\n",
    "for i, ann in enumerate(anns):\n",
    "    label_converter_dict[ann] = i #convert to zero-indexed labels\n",
    "#label_converter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f82aef-04a6-4269-b4c7-1a51f1b6161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000000011197.jpg', '000000009769.jpg', '000000009590.jpg', '000000011197.jpg', '000000016439.jpg', '000000018150.jpg', '000000018380.jpg', '000000019042.jpg', '000000061268.jpg', '000000063602.jpg', '000000067616.jpg', '000000119445.jpg', '000000119516.jpg', '000000186422.jpg', '000000203864.jpg', '000000209530.jpg', '000000222299.jpg', '000000226417.jpg', '000000255165.jpg', '000000281409.jpg', '000000311002.jpg', '000000322163.jpg', '000000484351.jpg', '000000491008.jpg', '000000509258.jpg', '000000529148.jpg', '000000545100.jpg']\n"
     ]
    }
   ],
   "source": [
    "## Load In Mongrel Pairs\n",
    "\n",
    "## read in data info\n",
    "bbx_list = pd.read_csv('./psychophysics_experiment/cocop_bbx_fixations_new.csv')\n",
    "\n",
    "#imlist = list(set(list(bbx_list['image_name'])))\n",
    "#imlist = ['000000009590.jpg','000000529148.jpg','000000545100.jpg','000000255165.jpg','000000322163.jpg'] #'000000311002.jpg', <- fix this one, it's 10 mongrels of the mask\n",
    "imlist = ['000000011197.jpg','000000009769.jpg','000000009590.jpg','000000011197.jpg','000000016439.jpg',\n",
    "'000000018150.jpg','000000018380.jpg','000000019042.jpg',\n",
    "'000000061268.jpg','000000063602.jpg','000000067616.jpg','000000119445.jpg',\n",
    "'000000119516.jpg','000000186422.jpg','000000203864.jpg',\n",
    "'000000209530.jpg','000000222299.jpg','000000226417.jpg','000000255165.jpg','000000281409.jpg',\n",
    "'000000311002.jpg','000000322163.jpg',\n",
    "'000000484351.jpg','000000491008.jpg','000000509258.jpg','000000529148.jpg','000000545100.jpg']\n",
    "print(imlist)\n",
    "\n",
    "eccs_px = [0,80,160,240,320] \n",
    "eccs_dg = [0,5,10,15,20]\n",
    "\n",
    "#imfolder = f'~/RosenholtzLab_shared/uniform_absent_exp_stims/ecc_{eccpx}/mongrel_{imname}_inpaint_ecc_{eccpx}_{n}.jpg' #present/absent/uni_{eccdg}/mongrel_{imname}_ecc_{eccdg}.jpg\n",
    "#imfolder = f'~/RosenholtzLab_shared/detection_repos/detrex/cocop_stims/' #present/absent/uni_{eccdg}/mongrel_{imname}_ecc_{eccdg}.jpg\n",
    "#imfolder = '~/RosenholtzLab_shared/cocop_stims3_scoring/uniform/'\n",
    "#absent/samples/ecc320/mongrel_000000545100_ecc_320_4.jpg\n",
    "#imfolder_present = f'~/RosenholtzLab_shared/final_experiment_mulitple_mongrel_images_present/'\n",
    "#imfolder_absent = f'~/RosenholtzLab_shared/final_experiment_mulitple_mongrel_images_present/'\n",
    "imfolder_present = '/home/gridsan/groups/RosenholtzLab/final_experiment_multiple_mongrel_images_present/'\n",
    "imfolder_absent = '/home/gridsan/groups/RosenholtzLab/final_experiment_multiple_mongrel_images_absent/'\n",
    "#imfolder_present = imfolder_absent = imfolder = '/home/gridsan/groups/RosenholtzLab/cocop_stims3_scoring/uniform/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc4bb8f1-3073-427b-a29b-c05c097edaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Model Stuff\n",
    "def create_predictor(ecc,thresh):\n",
    "    #baseline model\n",
    "    cfg = get_cfg()\n",
    "    # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "    #cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    #cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    #cfg.merge_from_file('./detectron2/configs/quick_schedules/mask_rcnn_R_50_FPN_inference_acc_test.yaml')\n",
    "    cfg.merge_from_file('./detectron2/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml')\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = thresh #0.01  # set threshold for this model\n",
    "    #cfg.MODEL.RETINANET.SCORE_THRESH_TEST = thresh\n",
    "    # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "    #cfg.MODEL.WEIGHTS = f'/{base_dir}detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl'\n",
    "    if(ecc=='-2'):\n",
    "        print('scratchtrain model')        \n",
    "        cfg.MODEL.WEIGHTS = f'/{base_dir}/output_trainscratch/trainscratch_ecc100/model_final.pth'\n",
    "\n",
    "    elif(ecc=='-1'):\n",
    "        #baseline\n",
    "        print('baseline model')\n",
    "        cfg.MODEL.WEIGHTS = f'/{base_dir}/detectron2/model_weights/R_50_FPN_3x/model_final_280758.pkl'\n",
    "    # elif(ecc=='100'):\n",
    "    #     cfg.MODEL.WEIGHTS = f'/{base_dir}/finetune_ecc{ecc}/model_final.pth'\n",
    "    else:\n",
    "        cfg.MODEL.WEIGHTS = f'/{base_dir}/finetune_ecc{ecc}/model_final.pth'\n",
    "    #cfg.SOLVER.BASE_LR = 0.0001 #0.001 \n",
    "    #model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "    \n",
    "    # pass in the bounding box\n",
    "    cfg.MODEL.PROPOSAL_GENERATOR.NAME = \"PrecomputedProposals\"\n",
    "    cfg.freeze()\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    return(cfg, predictor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dd6bafd-f17c-4f70-bffb-8b8275a3b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mong_lists(imname,ecc):\n",
    "    imname = imname.replace('.jpg','')\n",
    "\n",
    "    present_mongs = []\n",
    "    absent_mongs = []\n",
    "    #present & absent\n",
    "    if ecc==0:\n",
    "        nmongs = 1\n",
    "    else:\n",
    "        nmongs = 10\n",
    "    \n",
    "    for i in range(nmongs):\n",
    "        try:\n",
    "            if(ecc==0):\n",
    "                pmong = cv2.imread(os.path.join(imfolder_present,f'ecc{ecc}/{imname}.jpg'))\n",
    "            else:\n",
    "                pmong = cv2.imread(os.path.join(imfolder_present,f'ecc{ecc}/mongrel_{imname}_ecc_{ecc}_{i}.jpg'))\n",
    "            present_mongs.append(pmong)\n",
    "        except:\n",
    "            print(os.path.join(imfolder_present,f'ecc{ecc}/mongrel_{imname}_ecc_{ecc}_{i}.jpg'))\n",
    "        try:\n",
    "            if(ecc==0):\n",
    "                among = cv2.imread(os.path.join(imfolder_absent,f'ecc{ecc}/{imname}.png'))\n",
    "            else:                \n",
    "                among = cv2.imread(os.path.join(imfolder_absent,f'ecc{ecc}/mongrel_{imname}_ecc_{ecc}_{i}.jpg'))\n",
    "            #among = cv2.cvtColor(among, cv2.COLOR_BGR2RGB)\n",
    "            absent_mongs.append(among)\n",
    "        except:\n",
    "            print(os.path.join(imfolder_absent,f'ecc{ecc}/mongrel_{imname}_ecc_{ecc}_{i}.jpg'))\n",
    "\n",
    "        \n",
    "    return(present_mongs, absent_mongs)\n",
    "\n",
    "#present_mongs, absent_mongs = gen_mong_lists(imlist[2],160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce4eeac9-8404-4aa9-964c-269dd1cf63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropbbxtoimage(bbx,imsz):\n",
    "    '''\n",
    "    If bounding box extends outside image size, crop it.\n",
    "    '''\n",
    "    x,y,w,h = bbx\n",
    "    #print(imsz)\n",
    "    imx,imy,_ = imsz\n",
    "    x=0 if x<0 else x #make sure x isn't negative\n",
    "    y=0 if y<0 else y #make sure y isn't negative\n",
    "    w=imx if w+x>imx else w #make sure width isn't larger than image\n",
    "    h=imy if h+y>imy else h #make sure height isn't taller than image\n",
    "    return([x,y,w,h])\n",
    "\n",
    "def bbx_xywhtoxyxy(bbx):\n",
    "    x,y,w,h = bbx\n",
    "    x2 = x + w\n",
    "    y2 = y + h\n",
    "    return([x,y,x2,y2])\n",
    "\n",
    "def bbx_xyxytoxywh(bbx):\n",
    "    x,y,x2,y2 = bbx\n",
    "    w = x2-x\n",
    "    h = y2-y\n",
    "    return([x,y,w,h])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bda4d04-4e21-4e12-8912-8c0b7e616a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_match(model_predictions,\n",
    "                         ground_truth_object_id,\n",
    "                         ground_truth_bbx,\n",
    "                         padded_ground_truth_bbx,\n",
    "                         mong=None,\n",
    "                        enforce_category=True):\n",
    "    #find where ground truth object identity matches model class predictions\n",
    "    model_class_predictions = np.array(model_predictions['instances'].pred_classes.cpu())\n",
    "    \n",
    "    if(enforce_category):\n",
    "        prediction_matches = model_predictions['instances'][model_predictions['instances'].pred_classes==ground_truth_object_id]\n",
    "    else:\n",
    "        prediction_matches = model_predictions['instances']\n",
    "\n",
    "    if len(prediction_matches) == 0:\n",
    "        return(0.)\n",
    "    #otherwise find the best match\n",
    "    else:\n",
    "\n",
    "        best_match_pred = 0.\n",
    "        #loop through matches and return the highest one that operlaps\n",
    "        for i in range(len(prediction_matches)):\n",
    "            pred = prediction_matches[i]\n",
    "            model_bbx_predictions = pred.pred_boxes\n",
    "           \n",
    "            ioa = boxes.pairwise_ioa(padded_ground_truth_bbx, model_bbx_predictions)\n",
    "            ioa = np.array(ioa.cpu().numpy())[0][0]\n",
    "            \n",
    "            #print('iou is',iou)\n",
    "            #condition 1\n",
    "            if ioa > 0.75:\n",
    "                #condition 2\n",
    "                areas_ratio = ground_truth_bbx.area()/model_bbx_predictions.area()\n",
    "                if (areas_ratio > 0.5) and (areas_ratio < 2.): #0.6/1.67 #0.75/1.33 #0.9/1.11 #0.5/2\n",
    "                    score = pred.scores.cpu().numpy()[0]\n",
    "                    #print(score)\n",
    "                    #if thats our best score, keep it\n",
    "                    if score > best_match_pred:\n",
    "                        #print('updating score to',score)\n",
    "                        best_match_pred = score\n",
    "        #print('best',best_match_pred)\n",
    "        if mong is not None:\n",
    "            plt.show()\n",
    "\n",
    "    #if more than one report the highest\n",
    "    return(best_match_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0243e3a2-727f-49a2-af41-b8a578221894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_matches_no_threshold(model_predictions,\n",
    "                                       ground_truth_object_id):\n",
    "    model_class_predictions = model_predictions['instances'].pred_classes.detach().cpu()\n",
    "    model_scores = model_predictions['instances'].scores.detach().cpu()\n",
    "    \n",
    "    target_class_idx = (model_class_predictions == ground_truth_object_id).nonzero(as_tuple=True)[0].item()\n",
    "    return model_scores[target_class_idx].item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "105cf262-f41e-4d0f-97d3-107e7ca28acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_probabilities(pmong_prob, among_prob, nsamples):\n",
    "\n",
    "    if(pmong_prob==0. and among_prob==0.):\n",
    "        norm_among_prob = 0.5\n",
    "    elif(pmong_prob==0.):\n",
    "        norm_among_prob = 1.\n",
    "    elif(among_prob==0.):\n",
    "        norm_among_prob = 0.\n",
    "    else:\n",
    "        norm_among_prob = among_prob / (pmong_prob + among_prob)\n",
    "    #print(norm_among_prob)\n",
    "    samples = [np.random.rand() for i in range(nsamples)]\n",
    "    #if random [0,1] is greater than norm_among_prob then it's correct\n",
    "    #print(samples)\n",
    "    #print(norm_among_prob)\n",
    "    correct_preds = 1*np.greater(samples,norm_among_prob)\n",
    "    #print(correct_preds)\n",
    "    acc = np.mean(correct_preds)\n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb656a58-d628-4232-bd52-4515f956ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "def sample_probabilities_sdt(pmong_prob, among_prob, nsamples):\n",
    "    \n",
    "    #probability can't be exacly zero\n",
    "    pmong_prob = pmong_prob if pmong_prob>=1e-5 else 1e-5\n",
    "    among_prob = among_prob if among_prob>=1e-5 else 1e-5\n",
    "\n",
    "    #calcluate z scores\n",
    "    among_z = norm.ppf(q=(among_prob)) #ppd takes lower tail probability, among_prob is upper.\n",
    "    pmong_z = norm.ppf(q=(pmong_prob)) #ppd takes lower tail probability, pmong_prob is upper.\n",
    "    \n",
    "    d_prime = pmong_z - among_z #d prime is difference beween the two\n",
    "    \n",
    "    #print('among_z: ',among_z)\n",
    "    #print('pmong_z: ',pmong_z)\n",
    "    #print('d_prime: ',d_prime)\n",
    "    \n",
    "    among_dist_samples = np.random.normal(loc=0,size=nsamples) #sample from normal for among dist\n",
    "    pmong_dist_samples = np.random.normal(loc=d_prime,size=nsamples) #sample from normal for pmong dist\n",
    "    \n",
    "    #print('absent samples: ',among_dist_samples)\n",
    "    #print('present samples: ',pmong_dist_samples)\n",
    "    correct = 1*np.greater(pmong_dist_samples, among_dist_samples) #check if pmong was higher\n",
    "    acc = np.mean(correct)\n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a5006c-47a3-4784-9cea-80417758f9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_names = ['-1','0','-2','100','101','5','10','15','20']\n",
    "#finished: '100','-1',\n",
    "#model_names = ['101']#,'-2','5','10','15']\n",
    "nsamples = 1000\n",
    "pred_thresh = 0.0 # 0.1\n",
    "category_match_bool = False\n",
    "\n",
    "accuracies = {}\n",
    "for mi, model_name in enumerate(model_names):\n",
    "    accuracies[model_name] = {}\n",
    "    #create predictor\n",
    "    cfg, predictor = create_predictor(model_name,thresh=pred_thresh)\n",
    "    for im in imlist:\n",
    "        #make a dictionary\n",
    "        accuracies[model_name][im] = {}\n",
    "        for ecci, ecc in enumerate(eccs_px):\n",
    "            accuracies[model_name][im][ecc] = {}\n",
    "            present_mongs, absent_mongs = gen_mong_lists(im,ecc)\n",
    "            #store accuracy array for pairs of this mongrel + eccentricity combo\n",
    "            im_ecc_accuracies = []\n",
    "\n",
    "            ###### Run Inference on model (in parallel)\n",
    "            #pmong_model_predictions_batch = predictor(torch.from_numpy(np.array(present_mongs)))\n",
    "            #among_model_predictions_batch = predictor(torch.from_numpy(np.array(absent_mongs)))\n",
    "            \n",
    "            #loop through pairs            \n",
    "            for i in range(len(present_mongs)):\n",
    "                for j in range(len(absent_mongs)):\n",
    "                    #print(i,j)\n",
    "                    pmong = present_mongs[i]\n",
    "                    among = absent_mongs[j]\n",
    "                    \n",
    "                    # manually apply image pre-processing\n",
    "                    import detectron2.data.transforms as T\n",
    "                    with torch.no_grad():  # https://github.com/sphinx-doc/sphinx/issues/4258\n",
    "                        pheight, pwidth = pmong.shape[:2]\n",
    "                        aheight, awidth = among.shape[:2]\n",
    "                        # aug = T.ResizeShortestEdge(\n",
    "                        #         [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST\n",
    "                        #     )\n",
    "                        # image = aug.get_transform(original_image).apply_image(original_image)\n",
    "                        pmong = torch.as_tensor(pmong.astype(\"float32\").transpose(2, 0, 1))\n",
    "                        among = torch.as_tensor(among.astype(\"float32\").transpose(2, 0, 1))\n",
    "                        pinputs = {\"image\": pmong, \"height\": pheight, \"width\": pwidth}\n",
    "                        ainputs = {\"image\": among, \"height\": aheight, \"width\": awidth}   \n",
    "\n",
    "                    ##### Get Ground Truth\n",
    "                    #get ground truth bounding box\n",
    "                    ground_truth_bbx = [bbx_list[bbx_list['image_name']==im]['bbx_x_16'].item(),\n",
    "                                       bbx_list[bbx_list['image_name']==im]['bbx_y_16'].item(),\n",
    "                                       bbx_list[bbx_list['image_name']==im]['bbx_w_16'].item(),\n",
    "                                       bbx_list[bbx_list['image_name']==im]['bbx_h_16'].item()]\n",
    "                    #padded_ground_truth_bbx = ground_truth_bbx\n",
    "                    padded_ground_truth_bbx = [sum(x) for x in zip(ground_truth_bbx, [-ecc//4, #move x half a pooling region to left\n",
    "                                                                                  -ecc//4, #move y half a pooling region to right\n",
    "                                                                                   ecc//2, #increase width by full pooling region\n",
    "                                                                                   ecc//2] #increase height by full pooling region\n",
    "                                       )]\n",
    "                    #crop bbx if it extends beyond edge of image\n",
    "                    padded_ground_truth_bbx = cropbbxtoimage(ground_truth_bbx,pmong.shape)\n",
    "                    #print(print('bbx before',ground_truth_bbx))\n",
    "                    padded_ground_truth_bbx = bbx_xywhtoxyxy(padded_ground_truth_bbx)\n",
    "                    #print(print('bbx after',ground_truth_bbx))\n",
    "                    #convert to detectron2 Boxes for IOU calculation\n",
    "                    padded_ground_truth_bbx = boxes.Boxes(torch.unsqueeze(torch.Tensor(padded_ground_truth_bbx),0).to(device))\n",
    "\n",
    "                    #convert original ground truth bounding box also\n",
    "                    ground_truth_bbx = bbx_xywhtoxyxy(ground_truth_bbx)\n",
    "                    ground_truth_bbx = boxes.Boxes(torch.unsqueeze(torch.Tensor(ground_truth_bbx),0).to(device))\n",
    "                    \n",
    "                    #ground truth object category & ID\n",
    "                    ground_truth_object_name = bbx_list[bbx_list['image_name']==im]['object_name'].item()\n",
    "                    ground_truth_object_id = label_converter_dict[ground_truth_object_name]\n",
    "                    \n",
    "                    # fix a proposal bounding box\n",
    "                    from detectron2.structures import Boxes, Instances\n",
    "                    pres = Instances((pheight, pwidth))\n",
    "                    pres.proposal_boxes = padded_ground_truth_bbx\n",
    "                    pproposals = pres\n",
    "                    \n",
    "                    ares = Instances((aheight, awidth))\n",
    "                    ares.proposal_boxes = padded_ground_truth_bbx\n",
    "                    aproposals = ares\n",
    "\n",
    "                    # add box proposal to predictor inputs\n",
    "                    pinputs['proposals'] = pproposals\n",
    "                    ainputs['proposals'] = aproposals\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    pmong_model_predictions = predictor.model([pinputs])[0]\n",
    "                    among_model_predictions = predictor.model([ainputs])[0]\n",
    "                    \n",
    "                    pmong_prob = get_prediction_matches_no_threshold(pmong_model_predictions,ground_truth_object_id)\n",
    "                    among_prob = get_prediction_matches_no_threshold(among_model_predictions,ground_truth_object_id)\n",
    "                    print(pmong_prob, among_prob, padded_ground_truth_bbx)\n",
    "\n",
    "                    #pmong=cv2.cvtColor(pmong, cv2.COLOR_BGR2RGB)\n",
    "                    pmong=None\n",
    "            \n",
    "                    acc = float(pmong_prob > among_prob)\n",
    "                    im_ecc_accuracies.append(acc)\n",
    "            im_ecc_accuracies = np.array(im_ecc_accuracies)\n",
    "            if(ecc==0):\n",
    "                mean = im_ecc_accuracies[0]\n",
    "                std = np.nan\n",
    "            else:\n",
    "                mean = np.nanmean(im_ecc_accuracies)\n",
    "                std = np.nanstd(im_ecc_accuracies)\n",
    "            accuracies[model_name][im][ecc] = {'mean': mean,\n",
    "                                               'std': std,\n",
    "                                               'raw': im_ecc_accuracies}\n",
    "            mn = accuracies[model_name][im][ecc]['mean']\n",
    "            print(f'accuracy for model {model_name} for {im} at ecc {ecc} is {mn}')\n",
    "            #print(accuracies)\n",
    "    pkl_file = f'{base_dir}/machine_psychophysics_accuracies_full_sdt_model{model_name}_catmatch_{category_match_bool}.pickle'\n",
    "    file = open(pkl_file,'wb')\n",
    "    pickle.dump(accuracies[model_name],file)\n",
    "    file.close()\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de1e71a-cc0e-4018-a34f-8ac784c9b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add this model's evlation to previous ones\n",
    "import pickle\n",
    "pkl_file = f'/{base_dir}/machine_psychophysics_accuracies_full_sdt_catmatch_{category_match_bool}.pickle'\n",
    "file = open(pkl_file,'wb')\n",
    "pickle.dump(accuracies,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06163096-1dad-41e5-bb47-7fe69c8c7cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
